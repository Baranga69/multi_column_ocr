{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pytesseract import Output\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "image = cv2.imread(\"michael_jordan_stats.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constructing the arguments parser and parsing the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -i IMAGE -o OUTPUT [-c MIN_CONF]\n",
      "                             [-d DIST_THRESH] [-s MIN_SIZE]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -i/--image, -o/--output\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "    help=\"path to input image to be OCR'd\")\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "    help=\"path to output CSV file\")\n",
    "ap.add_argument(\"-c\", \"--min-conf\", type=int, default=0,\n",
    "    help = \"minimum confidence value to filter weak text detection\")\n",
    "ap.add_argument(\"-d\",\"--dist-thresh\", type=float, default=25.0,\n",
    "    help=\"distance threshold cutoff for clustering\")\n",
    "ap.add_argument(\"-s\", \"--min-size\", type=int, default=2,\n",
    "    help=\"minimum cluster size (i.e., # of entries in column)\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for our random number generator\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image and convert it to grayscale\n",
    "image = cv2.imread(args[\"image\"])\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a rectangular kernel that is ~5x wider than it is tall,\n",
    "# then smooth the image using a 3*3 Gaussian blur and then apply a\n",
    "# blackaht morphological operator to find dark regions on a light background\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (51,11))\n",
    "gray = cv2.GaussianBlur(gray, (3,3),0)\n",
    "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Scharr gradient of the blackhat image and scale the \n",
    "# result into the range [0, 255]\n",
    "\n",
    "grad = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "grad = np.abs(grad)\n",
    "(minVal, maxVal) = (np.min(grad), np.max(grad))\n",
    "grad = (grad - minVal) / (maxVal - minVal)\n",
    "grad = (grad * 255).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a closing operation using the rectangular kernel to close gaps in between\n",
    "# characters, apply Otsu's thresholding method, and finally a dilation operation to\n",
    "# enlarge foreground regions\n",
    "\n",
    "grad = cv2.morphologyEx(grad, cv2.MORPH_CLOSE,kernel)\n",
    "thresh = cv2.threshold(grad, 0, 255,\n",
    "    cv2.THRESH_BINARY | cv2.THRESH_OTSU) [1]\n",
    "thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "cv2.imshow(\"Thresh\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the threshold image and grab the largest one,\n",
    "# which we will assume is the stats table\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "    cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "tableCnt = max(cnts, key=cv2.contourArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the bounding box coordinates of the stats table and extract\n",
    "# the table from the input image \n",
    "(x, y, w, h) = cv2.boundingRect(tableCnt)\n",
    "table = image[y:y + h, x:x + w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the original input image and extracted table to our screen\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"Table\", table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the PSM mode to detect sparse text, then localize text in the table\n",
    "options = \"--psm 6\"\n",
    "results = pytesseract.image_to_data(\n",
    "    cv2.cvtColor(table, cv2.COLOR_BGR2RGB),\n",
    "    config=options,\n",
    "    output_type=Output.DICT\n",
    ")\n",
    "\n",
    "# initalize a list to store the (x,y) -coordinates of the detected text along\n",
    "# with the OCR'd text itself\n",
    "coords = []\n",
    "ocrText = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over each of the individual text localizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i  in range(0, len(results[\"text\"])):\n",
    "    # extract the bounding box coordinates of the text region from the current results\n",
    "    x = results[\"left\"] [i]\n",
    "    y = results[\"top\"] [i]\n",
    "    w = results[\"width\"] [i]\n",
    "    h = results[\"height\"] [i]\n",
    "\n",
    "    # extract the OCR text itself along with the confidence of the text localozation\n",
    "    text = results[\"text\"] [i]\n",
    "    conf = int(results[\"conf\"] [i])\n",
    "\n",
    "    #filter out the weak confidence text localizations\n",
    "    if conf > args[\"min_conf\"]:\n",
    "        # update our text bounding box coordinates and OCR'd text, respectively\n",
    "        coords.append((x,y,w,h))\n",
    "        ocrText.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all x-coordinates from the text bounding boxes, setting the y-coordinate value to zero\n",
    "xCoords = [(c[0], 0) for c in coords]\n",
    "\n",
    "# apply hierarchical agglomerative clustering to the coordinates\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    affinity=\"manhattan\",\n",
    "    linkage=\"complete\",\n",
    "    distance_threshold=args[\"dist_thresh\"])\n",
    "clustering.fit(xCoords)\n",
    "\n",
    "# initialize our list of sorted clusters\n",
    "sortedClusters = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over each of the unique clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all clusters\n",
    "for l in np.unique(clustering.labels_):\n",
    "    # extract the indexes for the coordinates belonging to the current cluster\n",
    "    idxs = np.where(clustering.labels_ == 1) [0]\n",
    "\n",
    "    # verify that the cluster is sufficiently large\n",
    "    if len(idxs) > args[\"min_size\"]:\n",
    "        # compute the average x-coordinate value of the cluster and update\n",
    "        # our clusters list with the current label and the average x-coordinate\n",
    "        avg = np.average([coords[i][0] for i in idxs])\n",
    "        sortedClusters.append((l,avg))\n",
    "\n",
    "# sort the clusters by their average x-coordinate and initialize our data frame\n",
    "sortedClusters.sort(key=lambda x:x[1])\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the clusters again, this time in sorted order\n",
    "for (l, _) in sortedClusters:\n",
    "    # Extract the indexes for the coordinates belonging to the current cluster\n",
    "    idxs = np.where(clustering.labels_ == 1)[0]\n",
    "\n",
    "    # Extract the y-coordinates from the elements in the current cluster, then sort \n",
    "    # them from top to bottom\n",
    "    yCoords = [coords[i][1] for i in idxs]\n",
    "    sortedIdxs = idxs[np.argsort(yCoords)]\n",
    "\n",
    "    # generate a random color for the cluster\n",
    "    color = np.random.randint(0,255, size=(3,), dtype=\"int\")\n",
    "    color = [int(c) for c in color]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the sorted indexes\n",
    "for i in sortedIdxs:\n",
    "    # Extract the text bounding coordinates and draw the bounding box surrounding the current element\n",
    "    (x, y, w, h) = coords[i]\n",
    "    cv2.rectangle(table, (x,y), (x + w, y + h), color, 2)\n",
    "\n",
    "# Extract the OCR'd text for the current column, then construct a data frame for the data where\n",
    "# the first entry in our column serves as the header\n",
    "cols = [ocrText[i].strip() for i in sortedIdxs]\n",
    "currentDF = pd.DataFrame({cols[0] : cols[1:]})\n",
    "\n",
    "# Concatenate *original* data frame with the *current* data frame\n",
    "# (we do this to handle columns that may have a varying number of rows)\n",
    "df = pd.concat([df, currentDF], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the table to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values with an empty string and then show a nicely \n",
    "# formatted version of our multi-column OCR'd text\n",
    "df.fillna(\"\", inplace=True)\n",
    "print(tabulate(df,headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "# Write our table to disk as a CSV file\n",
    "print(\"[INFO] saving CSV file to disk...\")\n",
    "df.to_csv(args[\"output\"], index=False)\n",
    "\n",
    "# Show the output image after performing multi-column OCR\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
